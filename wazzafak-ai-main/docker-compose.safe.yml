version: '3.8'

services:
  # Interview AI Backend - Connected to Supabase
  interview_backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: interview_backend
    environment:
      # Supabase PostgreSQL Connection String
      # Format: postgresql://postgres.[project-ref]:[password]@aws-0-[region].pooler.supabase.com:6543/postgres
      # Get your password from: Supabase Dashboard > Settings > Database > Connection string
      # Replace [YOUR_SUPABASE_DB_PASSWORD] with your actual database password
      # 
      # Option 1: Set via .env file (recommended)
      # Create .env file with: DATABASE_URL=postgresql://postgres.npeusanizvcyjwsgbhfn:[PASSWORD]@aws-0-[REGION].pooler.supabase.com:6543/postgres?sslmode=require
      #
      # Option 2: Set directly here (replace [YOUR-PASSWORD])
      # Using CONNECTION POOLING format (port 6543) - recommended for production
      # IMPORTANT: Replace with your own credentials before running!
      # Get from: Supabase Dashboard > Settings > Database > Connection string > Connection pooling
      # URL-encode special characters in password (? → %3F, @ → %40, # → %23)
      - DATABASE_URL=${DATABASE_URL}
      - USE_MOCK=${USE_MOCK:-0}
      # Get from: https://platform.openai.com/api-keys
      # Set USE_MOCK=0 and provide a real API key to enable real AI analysis
      - LLM_API_KEY=${LLM_API_KEY}
      # Leave empty for standard OpenAI API (default: https://api.openai.com/v1)
      # For Azure OpenAI: https://YOUR_RESOURCE.openai.azure.com/
      # For OpenRouter: https://openrouter.ai/api/v1
      # For other providers: use their API endpoint URL
      - LLM_BASE_URL=${LLM_BASE_URL:-}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-small}
      - CHAT_MODEL=${CHAT_MODEL:-gpt-4o-mini}
      - EVAL_MODEL=${EVAL_MODEL:-gpt-4o}
      - PORT=${PORT:-8089}
    ports:
      - "8089:8089"
    restart: unless-stopped

networks:
  default:
    name: interview_network

